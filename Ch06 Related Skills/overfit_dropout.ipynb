{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2919431102941132\n",
      "=== epoch:1, train acc:0.09666666666666666, test acc:0.0963 ===\n",
      "train loss:2.322061539993424\n",
      "train loss:2.3026482458672346\n",
      "train loss:2.332488817229961\n",
      "=== epoch:2, train acc:0.09, test acc:0.0965 ===\n",
      "train loss:2.2921877430138733\n",
      "train loss:2.3186899872465823\n",
      "train loss:2.2985349936162875\n",
      "=== epoch:3, train acc:0.09, test acc:0.0969 ===\n",
      "train loss:2.312861297146923\n",
      "train loss:2.3112676969623074\n",
      "train loss:2.302951793106955\n",
      "=== epoch:4, train acc:0.09333333333333334, test acc:0.0986 ===\n",
      "train loss:2.2785015668407813\n",
      "train loss:2.2984007583378645\n",
      "train loss:2.2883233878444345\n",
      "=== epoch:5, train acc:0.09333333333333334, test acc:0.1028 ===\n",
      "train loss:2.290213617518756\n",
      "train loss:2.29811231889735\n",
      "train loss:2.2945072308826995\n",
      "=== epoch:6, train acc:0.09333333333333334, test acc:0.1064 ===\n",
      "train loss:2.312930353316737\n",
      "train loss:2.312061418995638\n",
      "train loss:2.3138718583743336\n",
      "=== epoch:7, train acc:0.11333333333333333, test acc:0.1134 ===\n",
      "train loss:2.3108394628959332\n",
      "train loss:2.3213786869575253\n",
      "train loss:2.3026494424187574\n",
      "=== epoch:8, train acc:0.12333333333333334, test acc:0.12 ===\n",
      "train loss:2.306366810327852\n",
      "train loss:2.2967783441880645\n",
      "train loss:2.2874452781072603\n",
      "=== epoch:9, train acc:0.15, test acc:0.1289 ===\n",
      "train loss:2.3123137682360464\n",
      "train loss:2.303145978912407\n",
      "train loss:2.2802696430612137\n",
      "=== epoch:10, train acc:0.16, test acc:0.1345 ===\n",
      "train loss:2.309324516625135\n",
      "train loss:2.29416660430668\n",
      "train loss:2.291364588325258\n",
      "=== epoch:11, train acc:0.17, test acc:0.1406 ===\n",
      "train loss:2.310125649350566\n",
      "train loss:2.2719301611629277\n",
      "train loss:2.293966099337079\n",
      "=== epoch:12, train acc:0.17, test acc:0.1445 ===\n",
      "train loss:2.267499192556537\n",
      "train loss:2.2811443468766015\n",
      "train loss:2.2984990117774844\n",
      "=== epoch:13, train acc:0.17333333333333334, test acc:0.1449 ===\n",
      "train loss:2.3014982942699387\n",
      "train loss:2.302477923914602\n",
      "train loss:2.2932753596711573\n",
      "=== epoch:14, train acc:0.17, test acc:0.1454 ===\n",
      "train loss:2.2861362935564755\n",
      "train loss:2.277587001041311\n",
      "train loss:2.286404283084125\n",
      "=== epoch:15, train acc:0.18, test acc:0.1492 ===\n",
      "train loss:2.2877636566213635\n",
      "train loss:2.2817906326467563\n",
      "train loss:2.268316452689325\n",
      "=== epoch:16, train acc:0.17666666666666667, test acc:0.1543 ===\n",
      "train loss:2.2871042410410136\n",
      "train loss:2.2961919015861625\n",
      "train loss:2.290017676391892\n",
      "=== epoch:17, train acc:0.17333333333333334, test acc:0.1578 ===\n",
      "train loss:2.2847811914966663\n",
      "train loss:2.2825818779897338\n",
      "train loss:2.262395237166152\n",
      "=== epoch:18, train acc:0.18, test acc:0.1601 ===\n",
      "train loss:2.294606091266571\n",
      "train loss:2.2752013504991733\n",
      "train loss:2.3100674541289274\n",
      "=== epoch:19, train acc:0.18333333333333332, test acc:0.162 ===\n",
      "train loss:2.2768534236642544\n",
      "train loss:2.284312461979356\n",
      "train loss:2.2702513845592454\n",
      "=== epoch:20, train acc:0.18, test acc:0.1652 ===\n",
      "train loss:2.2703768891237504\n",
      "train loss:2.2829329142945802\n",
      "train loss:2.279847627012254\n",
      "=== epoch:21, train acc:0.18, test acc:0.168 ===\n",
      "train loss:2.290829240112825\n",
      "train loss:2.2754262604709874\n",
      "train loss:2.272127967555587\n",
      "=== epoch:22, train acc:0.19, test acc:0.1725 ===\n",
      "train loss:2.286784494646172\n",
      "train loss:2.274486384845085\n",
      "train loss:2.2855491226863096\n",
      "=== epoch:23, train acc:0.18666666666666668, test acc:0.1733 ===\n",
      "train loss:2.281743374771457\n",
      "train loss:2.269097792565889\n",
      "train loss:2.2664754525204187\n",
      "=== epoch:24, train acc:0.19, test acc:0.1748 ===\n",
      "train loss:2.2648319720459984\n",
      "train loss:2.284468840524682\n",
      "train loss:2.2835502688433627\n",
      "=== epoch:25, train acc:0.19666666666666666, test acc:0.1787 ===\n",
      "train loss:2.269170033828345\n",
      "train loss:2.2636969532993247\n",
      "train loss:2.2804464045089903\n",
      "=== epoch:26, train acc:0.19666666666666666, test acc:0.1784 ===\n",
      "train loss:2.276298740548719\n",
      "train loss:2.2331025985631134\n",
      "train loss:2.269538197833529\n",
      "=== epoch:27, train acc:0.20333333333333334, test acc:0.1771 ===\n",
      "train loss:2.2810431504616533\n",
      "train loss:2.293016684597475\n",
      "train loss:2.271933971664432\n",
      "=== epoch:28, train acc:0.20666666666666667, test acc:0.1787 ===\n",
      "train loss:2.276766492920998\n",
      "train loss:2.256377326986607\n",
      "train loss:2.2838472520262068\n",
      "=== epoch:29, train acc:0.21, test acc:0.1794 ===\n",
      "train loss:2.277269828873515\n",
      "train loss:2.263891965971216\n",
      "train loss:2.266380679490232\n",
      "=== epoch:30, train acc:0.21333333333333335, test acc:0.1816 ===\n",
      "train loss:2.2737300072114706\n",
      "train loss:2.2679218088659474\n",
      "train loss:2.291606540131136\n",
      "=== epoch:31, train acc:0.22333333333333333, test acc:0.1816 ===\n",
      "train loss:2.2679044266228328\n",
      "train loss:2.2748403217876025\n",
      "train loss:2.252135640818513\n",
      "=== epoch:32, train acc:0.22666666666666666, test acc:0.1842 ===\n",
      "train loss:2.259402423060027\n",
      "train loss:2.2706089467747845\n",
      "train loss:2.255258828943947\n",
      "=== epoch:33, train acc:0.22666666666666666, test acc:0.1864 ===\n",
      "train loss:2.2664843127778753\n",
      "train loss:2.2621010843881932\n",
      "train loss:2.259898710415704\n",
      "=== epoch:34, train acc:0.23, test acc:0.1919 ===\n",
      "train loss:2.257329163662103\n",
      "train loss:2.2637384712800586\n",
      "train loss:2.2496261683560563\n",
      "=== epoch:35, train acc:0.23666666666666666, test acc:0.1905 ===\n",
      "train loss:2.2813200111120158\n",
      "train loss:2.2816601123490745\n",
      "train loss:2.2604044584962817\n",
      "=== epoch:36, train acc:0.23666666666666666, test acc:0.195 ===\n",
      "train loss:2.2441419664846745\n",
      "train loss:2.2794901151209466\n",
      "train loss:2.262499558517068\n",
      "=== epoch:37, train acc:0.24, test acc:0.1959 ===\n",
      "train loss:2.26215087374427\n",
      "train loss:2.262102370238412\n",
      "train loss:2.269663996087692\n",
      "=== epoch:38, train acc:0.24333333333333335, test acc:0.1986 ===\n",
      "train loss:2.2542625446826503\n",
      "train loss:2.242364423842324\n",
      "train loss:2.251333202066637\n",
      "=== epoch:39, train acc:0.25, test acc:0.2036 ===\n",
      "train loss:2.2468465721033404\n",
      "train loss:2.2507989014397323\n",
      "train loss:2.254744557685708\n",
      "=== epoch:40, train acc:0.25333333333333335, test acc:0.2051 ===\n",
      "train loss:2.263366901995477\n",
      "train loss:2.2419016993056626\n",
      "train loss:2.2473589133142933\n",
      "=== epoch:41, train acc:0.25, test acc:0.207 ===\n",
      "train loss:2.2461156472321298\n",
      "train loss:2.273232108187324\n",
      "train loss:2.253225464249186\n",
      "=== epoch:42, train acc:0.25, test acc:0.208 ===\n",
      "train loss:2.238218617517486\n",
      "train loss:2.2416538614857435\n",
      "train loss:2.255836273635384\n",
      "=== epoch:43, train acc:0.26, test acc:0.2106 ===\n",
      "train loss:2.252513776501698\n",
      "train loss:2.2575316046007985\n",
      "train loss:2.260985047062606\n",
      "=== epoch:44, train acc:0.27, test acc:0.2133 ===\n",
      "train loss:2.2620318318372523\n",
      "train loss:2.2477379377282545\n",
      "train loss:2.265245056773329\n",
      "=== epoch:45, train acc:0.2733333333333333, test acc:0.2158 ===\n",
      "train loss:2.2545071736469406\n",
      "train loss:2.2684198176860106\n",
      "train loss:2.2510049747414143\n",
      "=== epoch:46, train acc:0.2833333333333333, test acc:0.2172 ===\n",
      "train loss:2.2575972879371045\n",
      "train loss:2.2451371130012236\n",
      "train loss:2.2611875156269585\n",
      "=== epoch:47, train acc:0.2866666666666667, test acc:0.2197 ===\n",
      "train loss:2.248084052341113\n",
      "train loss:2.2555184850723187\n",
      "train loss:2.241897413570795\n",
      "=== epoch:48, train acc:0.28, test acc:0.2179 ===\n",
      "train loss:2.2463166226040916\n",
      "train loss:2.238146051184861\n",
      "train loss:2.235542912745317\n",
      "=== epoch:49, train acc:0.28, test acc:0.2182 ===\n",
      "train loss:2.2359754363324513\n",
      "train loss:2.253655664495426\n",
      "train loss:2.233171851566819\n",
      "=== epoch:50, train acc:0.27, test acc:0.2175 ===\n",
      "train loss:2.2383220404823994\n",
      "train loss:2.2395106225089965\n",
      "train loss:2.2526892943381323\n",
      "=== epoch:51, train acc:0.26, test acc:0.2161 ===\n",
      "train loss:2.239611374009796\n",
      "train loss:2.2597407921551236\n",
      "train loss:2.2517675431135\n",
      "=== epoch:52, train acc:0.27, test acc:0.2181 ===\n",
      "train loss:2.2268150183985598\n",
      "train loss:2.2623480096958923\n",
      "train loss:2.241610238569636\n",
      "=== epoch:53, train acc:0.26666666666666666, test acc:0.2179 ===\n",
      "train loss:2.2450315819022757\n",
      "train loss:2.2494870828665317\n",
      "train loss:2.2408379020897877\n",
      "=== epoch:54, train acc:0.28, test acc:0.2213 ===\n",
      "train loss:2.2392370785929323\n",
      "train loss:2.2213041656775756\n",
      "train loss:2.23363367871054\n",
      "=== epoch:55, train acc:0.27666666666666667, test acc:0.2205 ===\n",
      "train loss:2.236044539158962\n",
      "train loss:2.2362421669446846\n",
      "train loss:2.2318052148295693\n",
      "=== epoch:56, train acc:0.27, test acc:0.2189 ===\n",
      "train loss:2.238314706659549\n",
      "train loss:2.2460074482258996\n",
      "train loss:2.2374282381537003\n",
      "=== epoch:57, train acc:0.2733333333333333, test acc:0.2223 ===\n",
      "train loss:2.2368904012908555\n",
      "train loss:2.2433024393020835\n",
      "train loss:2.221088550588876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:58, train acc:0.27666666666666667, test acc:0.2231 ===\n",
      "train loss:2.2261007681298857\n",
      "train loss:2.2134298790600115\n",
      "train loss:2.2403804859230023\n",
      "=== epoch:59, train acc:0.27666666666666667, test acc:0.224 ===\n",
      "train loss:2.2326960129533915\n",
      "train loss:2.245869575306119\n",
      "train loss:2.2509638116195103\n",
      "=== epoch:60, train acc:0.28, test acc:0.2267 ===\n",
      "train loss:2.255208865511359\n",
      "train loss:2.221365736045858\n",
      "train loss:2.219234075765822\n",
      "=== epoch:61, train acc:0.2833333333333333, test acc:0.2275 ===\n",
      "train loss:2.234743424684295\n",
      "train loss:2.244641485968103\n",
      "train loss:2.2423488531985574\n",
      "=== epoch:62, train acc:0.28, test acc:0.2258 ===\n",
      "train loss:2.2354992998465435\n",
      "train loss:2.2623726349470044\n",
      "train loss:2.2275157547876767\n",
      "=== epoch:63, train acc:0.29, test acc:0.2262 ===\n",
      "train loss:2.2335578709061323\n",
      "train loss:2.208485102615083\n",
      "train loss:2.2127028076471835\n",
      "=== epoch:64, train acc:0.28, test acc:0.2267 ===\n",
      "train loss:2.2226294064301486\n",
      "train loss:2.199888530965885\n",
      "train loss:2.223021750827604\n",
      "=== epoch:65, train acc:0.27666666666666667, test acc:0.2266 ===\n",
      "train loss:2.22837990569157\n",
      "train loss:2.2256492454929564\n",
      "train loss:2.2348781443119474\n",
      "=== epoch:66, train acc:0.2866666666666667, test acc:0.2289 ===\n",
      "train loss:2.221026058869474\n",
      "train loss:2.252877149527607\n",
      "train loss:2.2291098261471913\n",
      "=== epoch:67, train acc:0.2966666666666667, test acc:0.2374 ===\n",
      "train loss:2.215608703762536\n",
      "train loss:2.2346865680313464\n",
      "train loss:2.2128663353249136\n",
      "=== epoch:68, train acc:0.29333333333333333, test acc:0.2364 ===\n",
      "train loss:2.2119457538876497\n",
      "train loss:2.205317869106052\n",
      "train loss:2.2445493517017368\n",
      "=== epoch:69, train acc:0.3, test acc:0.2402 ===\n",
      "train loss:2.2282648782520895\n",
      "train loss:2.2371280022592317\n",
      "train loss:2.235883306742573\n",
      "=== epoch:70, train acc:0.31333333333333335, test acc:0.2479 ===\n",
      "train loss:2.2138070490925643\n",
      "train loss:2.219750731435853\n",
      "train loss:2.214785307781795\n",
      "=== epoch:71, train acc:0.31333333333333335, test acc:0.2497 ===\n",
      "train loss:2.2263897673967596\n",
      "train loss:2.208851035596453\n",
      "train loss:2.211229316930172\n",
      "=== epoch:72, train acc:0.31666666666666665, test acc:0.2539 ===\n",
      "train loss:2.2060754035136845\n",
      "train loss:2.215905676929734\n",
      "train loss:2.218575960947919\n",
      "=== epoch:73, train acc:0.32, test acc:0.2574 ===\n",
      "train loss:2.209616205625679\n",
      "train loss:2.210001884460854\n",
      "train loss:2.215585056009389\n",
      "=== epoch:74, train acc:0.31333333333333335, test acc:0.2594 ===\n",
      "train loss:2.215010372808042\n",
      "train loss:2.214287536938883\n",
      "train loss:2.1945428197374515\n",
      "=== epoch:75, train acc:0.31666666666666665, test acc:0.259 ===\n",
      "train loss:2.21715628925803\n",
      "train loss:2.187237015415443\n",
      "train loss:2.203737203204836\n",
      "=== epoch:76, train acc:0.32, test acc:0.2606 ===\n",
      "train loss:2.227920347474653\n",
      "train loss:2.2011415264747964\n",
      "train loss:2.220762450202221\n",
      "=== epoch:77, train acc:0.32666666666666666, test acc:0.2613 ===\n",
      "train loss:2.2082563446588344\n",
      "train loss:2.192336368125904\n",
      "train loss:2.1939069978214403\n",
      "=== epoch:78, train acc:0.32666666666666666, test acc:0.2644 ===\n",
      "train loss:2.243829720873591\n",
      "train loss:2.2165703798049887\n",
      "train loss:2.1791670492946817\n",
      "=== epoch:79, train acc:0.3333333333333333, test acc:0.2688 ===\n",
      "train loss:2.2093917452082086\n",
      "train loss:2.212366589893889\n",
      "train loss:2.206014717081126\n",
      "=== epoch:80, train acc:0.3433333333333333, test acc:0.2731 ===\n",
      "train loss:2.1983691252727353\n",
      "train loss:2.17947694897773\n",
      "train loss:2.207210410311622\n",
      "=== epoch:81, train acc:0.3466666666666667, test acc:0.273 ===\n",
      "train loss:2.1956725673797037\n",
      "train loss:2.1995281180669473\n",
      "train loss:2.2049836745128015\n",
      "=== epoch:82, train acc:0.35, test acc:0.2713 ===\n",
      "train loss:2.20440055664847\n",
      "train loss:2.173627527644606\n",
      "train loss:2.1929119608719008\n",
      "=== epoch:83, train acc:0.35333333333333333, test acc:0.2777 ===\n",
      "train loss:2.1764815199776337\n",
      "train loss:2.194187242283483\n",
      "train loss:2.2060914343646076\n",
      "=== epoch:84, train acc:0.36666666666666664, test acc:0.2846 ===\n",
      "train loss:2.186293813946556\n",
      "train loss:2.197347018378027\n",
      "train loss:2.2046055508699767\n",
      "=== epoch:85, train acc:0.37666666666666665, test acc:0.2877 ===\n",
      "train loss:2.2209319083095935\n",
      "train loss:2.2039327881405124\n",
      "train loss:2.185515078532765\n",
      "=== epoch:86, train acc:0.38, test acc:0.2958 ===\n",
      "train loss:2.1998204214566304\n",
      "train loss:2.208237173593042\n",
      "train loss:2.1700927252033653\n",
      "=== epoch:87, train acc:0.39, test acc:0.3014 ===\n",
      "train loss:2.1918470969338397\n",
      "train loss:2.2084329870255757\n",
      "train loss:2.1867639449818914\n",
      "=== epoch:88, train acc:0.4033333333333333, test acc:0.3105 ===\n",
      "train loss:2.2091896832162257\n",
      "train loss:2.185746069971909\n",
      "train loss:2.193123451203084\n",
      "=== epoch:89, train acc:0.4033333333333333, test acc:0.3123 ===\n",
      "train loss:2.1896261156182755\n",
      "train loss:2.1900275212386258\n",
      "train loss:2.201989016136061\n",
      "=== epoch:90, train acc:0.41, test acc:0.3164 ===\n",
      "train loss:2.2210671178067987\n",
      "train loss:2.1798248531358895\n",
      "train loss:2.1664357865311263\n",
      "=== epoch:91, train acc:0.4033333333333333, test acc:0.3133 ===\n",
      "train loss:2.1587721888935376\n",
      "train loss:2.184553314645448\n",
      "train loss:2.1712000084536727\n",
      "=== epoch:92, train acc:0.41333333333333333, test acc:0.3178 ===\n",
      "train loss:2.183322062812705\n",
      "train loss:2.172671628409399\n",
      "train loss:2.1730034692233153\n",
      "=== epoch:93, train acc:0.4033333333333333, test acc:0.319 ===\n",
      "train loss:2.172535260035109\n",
      "train loss:2.1844378553302253\n",
      "train loss:2.183003993149614\n",
      "=== epoch:94, train acc:0.4, test acc:0.3178 ===\n",
      "train loss:2.178619375607628\n",
      "train loss:2.1723066782755307\n",
      "train loss:2.196697369255867\n",
      "=== epoch:95, train acc:0.4, test acc:0.3173 ===\n",
      "train loss:2.1643461339167436\n",
      "train loss:2.184290383003516\n",
      "train loss:2.1781563750193222\n",
      "=== epoch:96, train acc:0.3933333333333333, test acc:0.3177 ===\n",
      "train loss:2.1553384001422105\n",
      "train loss:2.166069247944329\n",
      "train loss:2.191738328490132\n",
      "=== epoch:97, train acc:0.4033333333333333, test acc:0.3184 ===\n",
      "train loss:2.1705071978180097\n",
      "train loss:2.170412965808023\n",
      "train loss:2.1630387067213004\n",
      "=== epoch:98, train acc:0.4033333333333333, test acc:0.3189 ===\n",
      "train loss:2.1558862703685717\n",
      "train loss:2.1625296179852005\n",
      "train loss:2.168738711342523\n",
      "=== epoch:99, train acc:0.4066666666666667, test acc:0.318 ===\n",
      "train loss:2.1483702074163817\n",
      "train loss:2.1560011358740985\n",
      "train loss:2.159068573496189\n",
      "=== epoch:100, train acc:0.4066666666666667, test acc:0.3177 ===\n",
      "train loss:2.1435333612795917\n",
      "train loss:2.1811641741250485\n",
      "train loss:2.17180425279321\n",
      "=== epoch:101, train acc:0.4166666666666667, test acc:0.3237 ===\n",
      "train loss:2.1581853986128583\n",
      "train loss:2.1743374660125\n",
      "train loss:2.1470209611949507\n",
      "=== epoch:102, train acc:0.41333333333333333, test acc:0.3303 ===\n",
      "train loss:2.1809730711166764\n",
      "train loss:2.195373698440956\n",
      "train loss:2.177024526657196\n",
      "=== epoch:103, train acc:0.42, test acc:0.3325 ===\n",
      "train loss:2.2087419080292796\n",
      "train loss:2.191102552682501\n",
      "train loss:2.1822622725442247\n",
      "=== epoch:104, train acc:0.43666666666666665, test acc:0.3424 ===\n",
      "train loss:2.1561519254975092\n",
      "train loss:2.159586033397225\n",
      "train loss:2.14931499716884\n",
      "=== epoch:105, train acc:0.43333333333333335, test acc:0.3479 ===\n",
      "train loss:2.150265019656027\n",
      "train loss:2.1342808894098293\n",
      "train loss:2.1641310987181295\n",
      "=== epoch:106, train acc:0.43666666666666665, test acc:0.3473 ===\n",
      "train loss:2.153113735532987\n",
      "train loss:2.110558213922802\n",
      "train loss:2.1496344580198654\n",
      "=== epoch:107, train acc:0.43, test acc:0.3439 ===\n",
      "train loss:2.1457793600600317\n",
      "train loss:2.143761370232575\n",
      "train loss:2.1605681198597115\n",
      "=== epoch:108, train acc:0.43666666666666665, test acc:0.3483 ===\n",
      "train loss:2.1495233453664806\n",
      "train loss:2.151952016801968\n",
      "train loss:2.129965990280306\n",
      "=== epoch:109, train acc:0.44666666666666666, test acc:0.3455 ===\n",
      "train loss:2.1380194964102768\n",
      "train loss:2.122957088943304\n",
      "train loss:2.142589515438911\n",
      "=== epoch:110, train acc:0.44, test acc:0.3459 ===\n",
      "train loss:2.1380457793666214\n",
      "train loss:2.1412331318131637\n",
      "train loss:2.140270627190674\n",
      "=== epoch:111, train acc:0.44333333333333336, test acc:0.3476 ===\n",
      "train loss:2.1786454222056775\n",
      "train loss:2.1724423054470865\n",
      "train loss:2.141737065493752\n",
      "=== epoch:112, train acc:0.45, test acc:0.3522 ===\n",
      "train loss:2.159914518816309\n",
      "train loss:2.181012905686248\n",
      "train loss:2.1435076281172876\n",
      "=== epoch:113, train acc:0.45666666666666667, test acc:0.3571 ===\n",
      "train loss:2.1287892942844153\n",
      "train loss:2.1201820861134153\n",
      "train loss:2.1180334639081093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:114, train acc:0.4633333333333333, test acc:0.3605 ===\n",
      "train loss:2.139930231902365\n",
      "train loss:2.149179593691378\n",
      "train loss:2.150379938010352\n",
      "=== epoch:115, train acc:0.45666666666666667, test acc:0.3621 ===\n",
      "train loss:2.1189960487009283\n",
      "train loss:2.1689720872076723\n",
      "train loss:2.0947761440526396\n",
      "=== epoch:116, train acc:0.46, test acc:0.3621 ===\n",
      "train loss:2.1171746193747434\n",
      "train loss:2.113247943383069\n",
      "train loss:2.1168987619324517\n",
      "=== epoch:117, train acc:0.4533333333333333, test acc:0.3595 ===\n",
      "train loss:2.103693152678581\n",
      "train loss:2.107169550462107\n",
      "train loss:2.1464283378913227\n",
      "=== epoch:118, train acc:0.4633333333333333, test acc:0.3593 ===\n",
      "train loss:2.1694335767476614\n",
      "train loss:2.13088632091229\n",
      "train loss:2.11132904462327\n",
      "=== epoch:119, train acc:0.48, test acc:0.3675 ===\n",
      "train loss:2.1282722631718323\n",
      "train loss:2.1000173455012994\n",
      "train loss:2.143599204324965\n",
      "=== epoch:120, train acc:0.48333333333333334, test acc:0.3677 ===\n",
      "train loss:2.1264413476086275\n",
      "train loss:2.101145550502299\n",
      "train loss:2.1358874149493223\n",
      "=== epoch:121, train acc:0.4866666666666667, test acc:0.3709 ===\n",
      "train loss:2.1417384077316264\n",
      "train loss:2.133014452288732\n",
      "train loss:2.085824499730843\n",
      "=== epoch:122, train acc:0.4866666666666667, test acc:0.3726 ===\n",
      "train loss:2.1072110219119478\n",
      "train loss:2.073758564854983\n",
      "train loss:2.110399442032937\n",
      "=== epoch:123, train acc:0.48, test acc:0.3677 ===\n",
      "train loss:2.103749740179927\n",
      "train loss:2.109875822983645\n",
      "train loss:2.1124174526497637\n",
      "=== epoch:124, train acc:0.48333333333333334, test acc:0.3726 ===\n",
      "train loss:2.1470278064019976\n",
      "train loss:2.089847495019188\n",
      "train loss:2.093826467690199\n",
      "=== epoch:125, train acc:0.48333333333333334, test acc:0.374 ===\n",
      "train loss:2.11328272813143\n",
      "train loss:2.0936960233161535\n",
      "train loss:2.1159014248269035\n",
      "=== epoch:126, train acc:0.4866666666666667, test acc:0.3742 ===\n",
      "train loss:2.094275715643203\n",
      "train loss:2.1292983673513994\n",
      "train loss:2.1205177824067993\n",
      "=== epoch:127, train acc:0.49333333333333335, test acc:0.3817 ===\n",
      "train loss:2.0989387608462455\n",
      "train loss:2.1112007533234527\n",
      "train loss:2.0976053206364456\n",
      "=== epoch:128, train acc:0.49666666666666665, test acc:0.382 ===\n",
      "train loss:2.10962977186525\n",
      "train loss:2.0974961517466735\n",
      "train loss:2.1291514878431794\n",
      "=== epoch:129, train acc:0.49666666666666665, test acc:0.3846 ===\n",
      "train loss:2.0724676745931414\n",
      "train loss:2.08035912843941\n",
      "train loss:2.0849001936590663\n",
      "=== epoch:130, train acc:0.4866666666666667, test acc:0.3823 ===\n",
      "train loss:2.092210650839692\n",
      "train loss:2.108061602987295\n",
      "train loss:2.057685678014614\n",
      "=== epoch:131, train acc:0.49333333333333335, test acc:0.3894 ===\n",
      "train loss:2.075494045653204\n",
      "train loss:2.0712237521879584\n",
      "train loss:2.1154708097755774\n",
      "=== epoch:132, train acc:0.49666666666666665, test acc:0.3919 ===\n",
      "train loss:2.0949249576808238\n",
      "train loss:2.0741460794377637\n",
      "train loss:2.1011939096709416\n",
      "=== epoch:133, train acc:0.4866666666666667, test acc:0.3869 ===\n",
      "train loss:2.1105836314584545\n",
      "train loss:2.09690600697957\n",
      "train loss:2.110758734337138\n",
      "=== epoch:134, train acc:0.5066666666666667, test acc:0.3978 ===\n",
      "train loss:2.114753966498613\n",
      "train loss:2.0479522858041745\n",
      "train loss:2.0459667302764\n",
      "=== epoch:135, train acc:0.5033333333333333, test acc:0.3948 ===\n",
      "train loss:2.0835235980743496\n",
      "train loss:2.0921162982504793\n",
      "train loss:2.0534884307347263\n",
      "=== epoch:136, train acc:0.4866666666666667, test acc:0.3925 ===\n",
      "train loss:2.0914262846246108\n",
      "train loss:2.1136034338793364\n",
      "train loss:2.0980308318275998\n",
      "=== epoch:137, train acc:0.5033333333333333, test acc:0.4017 ===\n",
      "train loss:2.0737980363739394\n",
      "train loss:2.0615894403610557\n",
      "train loss:2.0648267009675685\n",
      "=== epoch:138, train acc:0.5, test acc:0.4001 ===\n",
      "train loss:2.0878720939534423\n",
      "train loss:2.064535801836075\n",
      "train loss:2.092143847581643\n",
      "=== epoch:139, train acc:0.5133333333333333, test acc:0.4124 ===\n",
      "train loss:2.1192513943113678\n",
      "train loss:2.057089387478342\n",
      "train loss:2.0280634155010393\n",
      "=== epoch:140, train acc:0.5166666666666667, test acc:0.415 ===\n",
      "train loss:2.0819840242395595\n",
      "train loss:2.099686109717639\n",
      "train loss:2.0550955227521426\n",
      "=== epoch:141, train acc:0.5166666666666667, test acc:0.4205 ===\n",
      "train loss:2.0941206325561974\n",
      "train loss:2.1169098124828256\n",
      "train loss:2.0464062251536417\n",
      "=== epoch:142, train acc:0.53, test acc:0.4255 ===\n",
      "train loss:2.058274055467482\n",
      "train loss:2.060991602393382\n",
      "train loss:2.0613073695250987\n",
      "=== epoch:143, train acc:0.5233333333333333, test acc:0.4257 ===\n",
      "train loss:2.062995881079773\n",
      "train loss:2.0760544184313154\n",
      "train loss:2.0658604512448413\n",
      "=== epoch:144, train acc:0.5233333333333333, test acc:0.4278 ===\n",
      "train loss:2.0275362546019027\n",
      "train loss:2.0323989571928816\n",
      "train loss:2.0395936400648687\n",
      "=== epoch:145, train acc:0.53, test acc:0.4253 ===\n",
      "train loss:2.0195165464501823\n",
      "train loss:2.023156659043082\n",
      "train loss:2.049459871690849\n",
      "=== epoch:146, train acc:0.52, test acc:0.4268 ===\n",
      "train loss:2.0802461724574686\n",
      "train loss:2.0621301838872856\n",
      "train loss:2.061211349541158\n",
      "=== epoch:147, train acc:0.53, test acc:0.4316 ===\n",
      "train loss:1.9875026221252374\n",
      "train loss:2.013260043449259\n",
      "train loss:2.034065830357282\n",
      "=== epoch:148, train acc:0.52, test acc:0.4252 ===\n",
      "train loss:1.99006655873334\n",
      "train loss:2.047833562012295\n",
      "train loss:2.0672958696140227\n",
      "=== epoch:149, train acc:0.5233333333333333, test acc:0.4206 ===\n",
      "train loss:2.046515390737445\n",
      "train loss:2.0117926337580627\n",
      "train loss:2.031064586319421\n",
      "=== epoch:150, train acc:0.53, test acc:0.4285 ===\n",
      "train loss:1.9913615717396536\n",
      "train loss:2.0455811402058313\n",
      "train loss:2.0367306103965785\n",
      "=== epoch:151, train acc:0.53, test acc:0.4255 ===\n",
      "train loss:2.047603027543223\n",
      "train loss:1.9924927867922755\n",
      "train loss:2.00347012850938\n",
      "=== epoch:152, train acc:0.53, test acc:0.4228 ===\n",
      "train loss:2.0715479138669126\n",
      "train loss:2.0239158815991445\n",
      "train loss:2.0049393775294644\n",
      "=== epoch:153, train acc:0.5266666666666666, test acc:0.4217 ===\n",
      "train loss:2.054936985188702\n",
      "train loss:2.049145379612849\n",
      "train loss:2.017970085595943\n",
      "=== epoch:154, train acc:0.5266666666666666, test acc:0.4249 ===\n",
      "train loss:1.9754675397074113\n",
      "train loss:2.070609804883332\n",
      "train loss:2.035128625158014\n",
      "=== epoch:155, train acc:0.5266666666666666, test acc:0.432 ===\n",
      "train loss:2.0150949443657673\n",
      "train loss:1.994704078137812\n",
      "train loss:2.051232201884267\n",
      "=== epoch:156, train acc:0.53, test acc:0.4328 ===\n",
      "train loss:1.9665116336647934\n",
      "train loss:1.9690327828002447\n",
      "train loss:2.0472549007844223\n",
      "=== epoch:157, train acc:0.5366666666666666, test acc:0.4398 ===\n",
      "train loss:2.0200703843220364\n",
      "train loss:1.9987544608559324\n",
      "train loss:1.9599717022587984\n",
      "=== epoch:158, train acc:0.5366666666666666, test acc:0.442 ===\n",
      "train loss:2.014615755102996\n",
      "train loss:1.9969164631958953\n",
      "train loss:1.9731511142043106\n",
      "=== epoch:159, train acc:0.54, test acc:0.4457 ===\n",
      "train loss:1.9917976883571853\n",
      "train loss:2.003366821718927\n",
      "train loss:1.992506518637169\n",
      "=== epoch:160, train acc:0.54, test acc:0.4485 ===\n",
      "train loss:1.984462787148705\n",
      "train loss:1.956422408027328\n",
      "train loss:1.9701113258511629\n",
      "=== epoch:161, train acc:0.55, test acc:0.4546 ===\n",
      "train loss:1.9657106632634942\n",
      "train loss:2.0081202622910888\n",
      "train loss:1.997213413569867\n",
      "=== epoch:162, train acc:0.5466666666666666, test acc:0.4598 ===\n",
      "train loss:1.959210795548389\n",
      "train loss:1.938997648181014\n",
      "train loss:1.9775136324996345\n",
      "=== epoch:163, train acc:0.5533333333333333, test acc:0.4596 ===\n",
      "train loss:1.9840429744592345\n",
      "train loss:1.9851175263945473\n",
      "train loss:2.0067805796905533\n",
      "=== epoch:164, train acc:0.56, test acc:0.4708 ===\n",
      "train loss:1.8966901151898201\n",
      "train loss:1.9566066852654693\n",
      "train loss:1.8970472822975113\n",
      "=== epoch:165, train acc:0.5533333333333333, test acc:0.4558 ===\n",
      "train loss:1.9920407990980957\n",
      "train loss:1.9383297376766497\n",
      "train loss:2.0058682668162318\n",
      "=== epoch:166, train acc:0.5666666666666667, test acc:0.465 ===\n",
      "train loss:1.9972768694480394\n",
      "train loss:1.972873604210861\n",
      "train loss:1.9462731966830034\n",
      "=== epoch:167, train acc:0.5633333333333334, test acc:0.4648 ===\n",
      "train loss:1.9955492705548727\n",
      "train loss:1.995222918825526\n",
      "train loss:1.9612551615001323\n",
      "=== epoch:168, train acc:0.5733333333333334, test acc:0.4745 ===\n",
      "train loss:1.9696109335086802\n",
      "train loss:1.912190344741748\n",
      "train loss:1.9043035784213698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:169, train acc:0.5633333333333334, test acc:0.4685 ===\n",
      "train loss:2.023946557831383\n",
      "train loss:1.9082864393326486\n",
      "train loss:1.9197020330395613\n",
      "=== epoch:170, train acc:0.56, test acc:0.4602 ===\n",
      "train loss:1.9877895541825612\n",
      "train loss:1.9334513434828104\n",
      "train loss:1.9111223000344493\n",
      "=== epoch:171, train acc:0.5633333333333334, test acc:0.4651 ===\n",
      "train loss:1.9762845349593632\n",
      "train loss:1.857211629816251\n",
      "train loss:1.9200509941990944\n",
      "=== epoch:172, train acc:0.5633333333333334, test acc:0.4638 ===\n",
      "train loss:1.9085335376898538\n",
      "train loss:1.9465912003565233\n",
      "train loss:1.98053547055334\n",
      "=== epoch:173, train acc:0.5633333333333334, test acc:0.4631 ===\n",
      "train loss:1.9253300066174563\n",
      "train loss:1.9521376782408746\n",
      "train loss:1.8443180115068238\n",
      "=== epoch:174, train acc:0.56, test acc:0.4681 ===\n",
      "train loss:1.8846789269389688\n",
      "train loss:1.9296976861686923\n",
      "train loss:1.9334840912706064\n",
      "=== epoch:175, train acc:0.5733333333333334, test acc:0.4751 ===\n",
      "train loss:1.8985864700318553\n",
      "train loss:1.8692114059501845\n",
      "train loss:1.9202287813178953\n",
      "=== epoch:176, train acc:0.5766666666666667, test acc:0.4799 ===\n",
      "train loss:1.8727533167488197\n",
      "train loss:1.9147319182584113\n",
      "train loss:1.9667578110676445\n",
      "=== epoch:177, train acc:0.5633333333333334, test acc:0.4802 ===\n",
      "train loss:1.9795182376704585\n",
      "train loss:1.841008541277208\n",
      "train loss:1.8935166540358617\n",
      "=== epoch:178, train acc:0.5733333333333334, test acc:0.4828 ===\n",
      "train loss:1.91036166759559\n",
      "train loss:1.8431067182785645\n",
      "train loss:1.848446686380865\n",
      "=== epoch:179, train acc:0.57, test acc:0.4866 ===\n",
      "train loss:1.8483371653206317\n",
      "train loss:1.8642157611456165\n",
      "train loss:1.9020282809634381\n",
      "=== epoch:180, train acc:0.5866666666666667, test acc:0.4921 ===\n",
      "train loss:1.866953906836016\n",
      "train loss:1.8843286407113546\n",
      "train loss:1.8977606311705677\n",
      "=== epoch:181, train acc:0.5733333333333334, test acc:0.4907 ===\n",
      "train loss:1.916644842721014\n",
      "train loss:1.9110440943456442\n",
      "train loss:1.8592087806648054\n",
      "=== epoch:182, train acc:0.5833333333333334, test acc:0.496 ===\n",
      "train loss:1.8057166943330805\n",
      "train loss:1.9098922006633314\n",
      "train loss:1.863602742527813\n",
      "=== epoch:183, train acc:0.5966666666666667, test acc:0.4976 ===\n",
      "train loss:1.8481754300399182\n",
      "train loss:1.8713425257275114\n",
      "train loss:1.8018290476502745\n",
      "=== epoch:184, train acc:0.5833333333333334, test acc:0.4957 ===\n",
      "train loss:1.9061567621607989\n",
      "train loss:1.8087320119613834\n",
      "train loss:1.8558067023402398\n",
      "=== epoch:185, train acc:0.58, test acc:0.4949 ===\n",
      "train loss:1.9099761948025609\n",
      "train loss:1.8490790986367793\n",
      "train loss:1.9025202114193633\n",
      "=== epoch:186, train acc:0.58, test acc:0.4967 ===\n",
      "train loss:1.8298745360441233\n",
      "train loss:1.8275934668985767\n",
      "train loss:1.8012496739117934\n",
      "=== epoch:187, train acc:0.5766666666666667, test acc:0.4981 ===\n",
      "train loss:1.8543451535566984\n",
      "train loss:1.9037454034037091\n",
      "train loss:1.8463609922597863\n",
      "=== epoch:188, train acc:0.5733333333333334, test acc:0.4988 ===\n",
      "train loss:1.8621345739708668\n",
      "train loss:1.7706440981105709\n",
      "train loss:1.8192378926606099\n",
      "=== epoch:189, train acc:0.5733333333333334, test acc:0.4948 ===\n",
      "train loss:1.822231244583765\n",
      "train loss:1.8384537524380904\n",
      "train loss:1.8130469757994658\n",
      "=== epoch:190, train acc:0.57, test acc:0.494 ===\n",
      "train loss:1.8247629592034398\n",
      "train loss:1.8193765242174174\n",
      "train loss:1.7888794655121207\n",
      "=== epoch:191, train acc:0.5733333333333334, test acc:0.4928 ===\n",
      "train loss:1.7667086036698685\n",
      "train loss:1.8033846071046509\n",
      "train loss:1.8107284672917365\n",
      "=== epoch:192, train acc:0.5733333333333334, test acc:0.4922 ===\n",
      "train loss:1.7815780478338539\n",
      "train loss:1.731928345616078\n",
      "train loss:1.7987775561147583\n",
      "=== epoch:193, train acc:0.5733333333333334, test acc:0.49 ===\n",
      "train loss:1.8486738590570646\n",
      "train loss:1.821520466249953\n",
      "train loss:1.7245681365453296\n",
      "=== epoch:194, train acc:0.5733333333333334, test acc:0.4911 ===\n",
      "train loss:1.8690676758149933\n",
      "train loss:1.8559300575472752\n",
      "train loss:1.8463007789675103\n",
      "=== epoch:195, train acc:0.59, test acc:0.5001 ===\n",
      "train loss:1.8097633606883181\n",
      "train loss:1.792435678186205\n",
      "train loss:1.7454402134863247\n",
      "=== epoch:196, train acc:0.6, test acc:0.5051 ===\n",
      "train loss:1.8087355352707093\n",
      "train loss:1.812084400402863\n",
      "train loss:1.7849699475148193\n",
      "=== epoch:197, train acc:0.6033333333333334, test acc:0.507 ===\n",
      "train loss:1.7864161874368865\n",
      "train loss:1.884025448705719\n",
      "train loss:1.8125555346587683\n",
      "=== epoch:198, train acc:0.6033333333333334, test acc:0.5084 ===\n",
      "train loss:1.7536362865292343\n",
      "train loss:1.7298279916973467\n",
      "train loss:1.8019992318513351\n",
      "=== epoch:199, train acc:0.61, test acc:0.5126 ===\n",
      "train loss:1.7582996112421094\n",
      "train loss:1.79245449574713\n",
      "train loss:1.726276678220407\n",
      "=== epoch:200, train acc:0.6, test acc:0.5078 ===\n",
      "train loss:1.8326278473825222\n",
      "train loss:1.7722749860824367\n",
      "train loss:1.734390190955767\n",
      "=== epoch:201, train acc:0.5966666666666667, test acc:0.5097 ===\n",
      "train loss:1.681532407674288\n",
      "train loss:1.730222890397952\n",
      "train loss:1.7181970933508584\n",
      "=== epoch:202, train acc:0.6066666666666667, test acc:0.5097 ===\n",
      "train loss:1.7540505903133063\n",
      "train loss:1.7177909127003046\n",
      "train loss:1.744560904201328\n",
      "=== epoch:203, train acc:0.61, test acc:0.5121 ===\n",
      "train loss:1.7404747364873898\n",
      "train loss:1.788370436363618\n",
      "train loss:1.7455038136045562\n",
      "=== epoch:204, train acc:0.6, test acc:0.5178 ===\n",
      "train loss:1.7328070500953943\n",
      "train loss:1.7321674935155391\n",
      "train loss:1.779568116987541\n",
      "=== epoch:205, train acc:0.6033333333333334, test acc:0.5156 ===\n",
      "train loss:1.6785822591252115\n",
      "train loss:1.7127096765938281\n",
      "train loss:1.7267363283466635\n",
      "=== epoch:206, train acc:0.6066666666666667, test acc:0.5178 ===\n",
      "train loss:1.7316370230076992\n",
      "train loss:1.7773486082029033\n",
      "train loss:1.6891635036618688\n",
      "=== epoch:207, train acc:0.5866666666666667, test acc:0.5168 ===\n",
      "train loss:1.7005876357031988\n",
      "train loss:1.806026537020282\n",
      "train loss:1.5976946189270722\n",
      "=== epoch:208, train acc:0.5866666666666667, test acc:0.5168 ===\n",
      "train loss:1.6944903950405887\n",
      "train loss:1.7840850659293852\n",
      "train loss:1.7184940428843358\n",
      "=== epoch:209, train acc:0.6066666666666667, test acc:0.5243 ===\n",
      "train loss:1.6910429276817251\n",
      "train loss:1.6956151300307214\n",
      "train loss:1.6718353067483298\n",
      "=== epoch:210, train acc:0.6, test acc:0.5249 ===\n",
      "train loss:1.701752208573739\n",
      "train loss:1.718074311787987\n",
      "train loss:1.7022457396216195\n",
      "=== epoch:211, train acc:0.61, test acc:0.529 ===\n",
      "train loss:1.6623051419318495\n",
      "train loss:1.7839238170948986\n",
      "train loss:1.755506913089188\n",
      "=== epoch:212, train acc:0.6033333333333334, test acc:0.5296 ===\n",
      "train loss:1.6771147794624934\n",
      "train loss:1.6469078369391406\n",
      "train loss:1.740013403443025\n",
      "=== epoch:213, train acc:0.61, test acc:0.5308 ===\n",
      "train loss:1.6869739046924201\n",
      "train loss:1.6658263902623924\n",
      "train loss:1.6896946760947749\n",
      "=== epoch:214, train acc:0.6233333333333333, test acc:0.5359 ===\n",
      "train loss:1.672020906571977\n",
      "train loss:1.634928498465174\n",
      "train loss:1.6118498804485675\n",
      "=== epoch:215, train acc:0.6233333333333333, test acc:0.534 ===\n",
      "train loss:1.5652356429165009\n",
      "train loss:1.673039033480015\n",
      "train loss:1.609226512449575\n",
      "=== epoch:216, train acc:0.6166666666666667, test acc:0.5315 ===\n",
      "train loss:1.649874291082679\n",
      "train loss:1.7680259997684054\n",
      "train loss:1.6615187803888014\n",
      "=== epoch:217, train acc:0.6133333333333333, test acc:0.5294 ===\n",
      "train loss:1.6272581347109099\n",
      "train loss:1.5086123855809965\n",
      "train loss:1.6332168868684585\n",
      "=== epoch:218, train acc:0.62, test acc:0.5273 ===\n",
      "train loss:1.5778396133137877\n",
      "train loss:1.6853054859748493\n",
      "train loss:1.551103161929235\n",
      "=== epoch:219, train acc:0.6133333333333333, test acc:0.5295 ===\n",
      "train loss:1.5609255728107359\n",
      "train loss:1.5658556280253058\n",
      "train loss:1.577786214241013\n",
      "=== epoch:220, train acc:0.6166666666666667, test acc:0.5287 ===\n",
      "train loss:1.6147467561227722\n",
      "train loss:1.6852972604240608\n",
      "train loss:1.6819946581571623\n",
      "=== epoch:221, train acc:0.6166666666666667, test acc:0.5295 ===\n",
      "train loss:1.6209254633946488\n",
      "train loss:1.557759744089928\n",
      "train loss:1.5915109471326474\n",
      "=== epoch:222, train acc:0.6166666666666667, test acc:0.5281 ===\n",
      "train loss:1.6321205299381747\n",
      "train loss:1.6499493551973572\n",
      "train loss:1.5917069858278179\n",
      "=== epoch:223, train acc:0.6166666666666667, test acc:0.5286 ===\n",
      "train loss:1.7137697438113535\n",
      "train loss:1.5415152929551965\n",
      "train loss:1.6770682062512576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:224, train acc:0.6233333333333333, test acc:0.5302 ===\n",
      "train loss:1.545942373692119\n",
      "train loss:1.6006700605759117\n",
      "train loss:1.5475873152291337\n",
      "=== epoch:225, train acc:0.62, test acc:0.5314 ===\n",
      "train loss:1.4452333454870196\n",
      "train loss:1.4941355545641486\n",
      "train loss:1.510740584068901\n",
      "=== epoch:226, train acc:0.62, test acc:0.5278 ===\n",
      "train loss:1.5724660044260268\n",
      "train loss:1.5737973001266412\n",
      "train loss:1.5751672631865452\n",
      "=== epoch:227, train acc:0.6233333333333333, test acc:0.5293 ===\n",
      "train loss:1.497599846702014\n",
      "train loss:1.603778517522571\n",
      "train loss:1.5513146723107811\n",
      "=== epoch:228, train acc:0.6266666666666667, test acc:0.5298 ===\n",
      "train loss:1.5519077288009375\n",
      "train loss:1.5689609324041534\n",
      "train loss:1.4871729943640761\n",
      "=== epoch:229, train acc:0.62, test acc:0.5306 ===\n",
      "train loss:1.3728564840086153\n",
      "train loss:1.498489324104475\n",
      "train loss:1.5584556145446047\n",
      "=== epoch:230, train acc:0.61, test acc:0.5304 ===\n",
      "train loss:1.3680072146252327\n",
      "train loss:1.5172286862154747\n",
      "train loss:1.4660537454736338\n",
      "=== epoch:231, train acc:0.6066666666666667, test acc:0.5259 ===\n",
      "train loss:1.6934688934522355\n",
      "train loss:1.5604930994533766\n",
      "train loss:1.5572608467539797\n",
      "=== epoch:232, train acc:0.61, test acc:0.5278 ===\n",
      "train loss:1.4931800177036567\n",
      "train loss:1.5057265557115582\n",
      "train loss:1.402542401929053\n",
      "=== epoch:233, train acc:0.6066666666666667, test acc:0.5249 ===\n",
      "train loss:1.52469825003519\n",
      "train loss:1.6542968546903518\n",
      "train loss:1.4747690734296384\n",
      "=== epoch:234, train acc:0.61, test acc:0.5258 ===\n",
      "train loss:1.4720016327888905\n",
      "train loss:1.4677440888898556\n",
      "train loss:1.488798338481474\n",
      "=== epoch:235, train acc:0.6133333333333333, test acc:0.5268 ===\n",
      "train loss:1.4752791565859489\n",
      "train loss:1.4841420349737657\n",
      "train loss:1.5159647319005092\n",
      "=== epoch:236, train acc:0.6233333333333333, test acc:0.5336 ===\n",
      "train loss:1.516444439084631\n",
      "train loss:1.4409989471694982\n",
      "train loss:1.5167801344148986\n",
      "=== epoch:237, train acc:0.62, test acc:0.5351 ===\n",
      "train loss:1.377536626165515\n",
      "train loss:1.4048950883202054\n",
      "train loss:1.419255274202093\n",
      "=== epoch:238, train acc:0.62, test acc:0.5347 ===\n",
      "train loss:1.3814224457233741\n",
      "train loss:1.424853751347789\n",
      "train loss:1.4384967999946248\n",
      "=== epoch:239, train acc:0.62, test acc:0.5349 ===\n",
      "train loss:1.4562191884790028\n",
      "train loss:1.3183097617613244\n",
      "train loss:1.4890597206785356\n",
      "=== epoch:240, train acc:0.6233333333333333, test acc:0.535 ===\n",
      "train loss:1.496040894101485\n",
      "train loss:1.4464602883106343\n",
      "train loss:1.365900939067239\n",
      "=== epoch:241, train acc:0.6233333333333333, test acc:0.5359 ===\n",
      "train loss:1.4463816590035217\n",
      "train loss:1.3724091593090486\n",
      "train loss:1.3568503992828769\n",
      "=== epoch:242, train acc:0.6233333333333333, test acc:0.5384 ===\n",
      "train loss:1.541589772673285\n",
      "train loss:1.3581569062088574\n",
      "train loss:1.4688320314046275\n",
      "=== epoch:243, train acc:0.6233333333333333, test acc:0.5427 ===\n",
      "train loss:1.4069781929023788\n",
      "train loss:1.4545321033536365\n",
      "train loss:1.3357429017733116\n",
      "=== epoch:244, train acc:0.6233333333333333, test acc:0.5399 ===\n",
      "train loss:1.4772607460905862\n",
      "train loss:1.5234390231378838\n",
      "train loss:1.3591259797716224\n",
      "=== epoch:245, train acc:0.6266666666666667, test acc:0.5393 ===\n",
      "train loss:1.3663003481959135\n",
      "train loss:1.2669403190591761\n",
      "train loss:1.3508265278800418\n",
      "=== epoch:246, train acc:0.6266666666666667, test acc:0.5379 ===\n",
      "train loss:1.3914770454738916\n",
      "train loss:1.4826134905955706\n",
      "train loss:1.520314953124238\n",
      "=== epoch:247, train acc:0.6266666666666667, test acc:0.5367 ===\n",
      "train loss:1.303260965378502\n",
      "train loss:1.4566705277125116\n",
      "train loss:1.4120268418928907\n",
      "=== epoch:248, train acc:0.6133333333333333, test acc:0.5414 ===\n",
      "train loss:1.4905877567133083\n",
      "train loss:1.2249274045382763\n",
      "train loss:1.3265027050822653\n",
      "=== epoch:249, train acc:0.62, test acc:0.5412 ===\n",
      "train loss:1.4424221147390892\n",
      "train loss:1.2722667390147335\n",
      "train loss:1.3723374418439611\n",
      "=== epoch:250, train acc:0.62, test acc:0.5428 ===\n",
      "train loss:1.3103786338881744\n",
      "train loss:1.3529008197672356\n",
      "train loss:1.307293132540451\n",
      "=== epoch:251, train acc:0.63, test acc:0.5442 ===\n",
      "train loss:1.272634335308089\n",
      "train loss:1.3996303839538917\n",
      "train loss:1.3129787974672187\n",
      "=== epoch:252, train acc:0.6366666666666667, test acc:0.5435 ===\n",
      "train loss:1.2039883750000282\n",
      "train loss:1.3248279012481874\n",
      "train loss:1.3653724615358758\n",
      "=== epoch:253, train acc:0.6433333333333333, test acc:0.5428 ===\n",
      "train loss:1.2599925127052571\n",
      "train loss:1.3327967479011955\n",
      "train loss:1.19646045177602\n",
      "=== epoch:254, train acc:0.6266666666666667, test acc:0.5429 ===\n",
      "train loss:1.3830677117168018\n",
      "train loss:1.2086068102541692\n",
      "train loss:1.3352308031887756\n",
      "=== epoch:255, train acc:0.64, test acc:0.5396 ===\n",
      "train loss:1.3468691568291666\n",
      "train loss:1.3552803861037748\n",
      "train loss:1.3187411059608352\n",
      "=== epoch:256, train acc:0.6433333333333333, test acc:0.5401 ===\n",
      "train loss:1.3597981436120425\n",
      "train loss:1.3371645164268455\n",
      "train loss:1.275193380308091\n",
      "=== epoch:257, train acc:0.6266666666666667, test acc:0.5399 ===\n",
      "train loss:1.4533979900671026\n",
      "train loss:1.3068711110456304\n",
      "train loss:1.1693345622429798\n",
      "=== epoch:258, train acc:0.63, test acc:0.542 ===\n",
      "train loss:1.3663879684347828\n",
      "train loss:1.2694619343404416\n",
      "train loss:1.3272426354284717\n",
      "=== epoch:259, train acc:0.6433333333333333, test acc:0.5403 ===\n",
      "train loss:1.2669369035414033\n",
      "train loss:1.2621013229097537\n",
      "train loss:1.1978195877760935\n",
      "=== epoch:260, train acc:0.6333333333333333, test acc:0.5421 ===\n",
      "train loss:1.4158532757413682\n",
      "train loss:1.3219869453807351\n",
      "train loss:1.2495808998314653\n",
      "=== epoch:261, train acc:0.6266666666666667, test acc:0.5424 ===\n",
      "train loss:1.330007789959653\n",
      "train loss:1.3473311409142459\n",
      "train loss:1.2975239328859374\n",
      "=== epoch:262, train acc:0.6366666666666667, test acc:0.5448 ===\n",
      "train loss:1.227820062120093\n",
      "train loss:1.358076308474687\n",
      "train loss:1.3432390074342464\n",
      "=== epoch:263, train acc:0.6366666666666667, test acc:0.5444 ===\n",
      "train loss:1.1968924758565664\n",
      "train loss:1.299788041755079\n",
      "train loss:1.2038513442814947\n",
      "=== epoch:264, train acc:0.6233333333333333, test acc:0.5444 ===\n",
      "train loss:1.2915073947893196\n",
      "train loss:1.272345615547845\n",
      "train loss:1.152323220296394\n",
      "=== epoch:265, train acc:0.6466666666666666, test acc:0.5482 ===\n",
      "train loss:1.163723145924537\n",
      "train loss:1.276419211226819\n",
      "train loss:1.300196294301869\n",
      "=== epoch:266, train acc:0.64, test acc:0.5498 ===\n",
      "train loss:1.2334120962013488\n",
      "train loss:1.2598990236130942\n",
      "train loss:1.334032221885205\n",
      "=== epoch:267, train acc:0.6366666666666667, test acc:0.5509 ===\n",
      "train loss:1.1176156162502788\n",
      "train loss:1.2198933364108446\n",
      "train loss:1.1586169970597386\n",
      "=== epoch:268, train acc:0.6533333333333333, test acc:0.5496 ===\n",
      "train loss:1.1855515409086377\n",
      "train loss:1.164020447750191\n",
      "train loss:1.2506742693537531\n",
      "=== epoch:269, train acc:0.65, test acc:0.5521 ===\n",
      "train loss:1.2506527935294212\n",
      "train loss:1.2584752684974594\n",
      "train loss:1.2509973803986327\n",
      "=== epoch:270, train acc:0.65, test acc:0.5524 ===\n",
      "train loss:1.2606420138484014\n",
      "train loss:1.1448799190489496\n",
      "train loss:1.2001720522186243\n",
      "=== epoch:271, train acc:0.6466666666666666, test acc:0.5534 ===\n",
      "train loss:1.1948436613179716\n",
      "train loss:1.1322298885212312\n",
      "train loss:1.0859954548679178\n",
      "=== epoch:272, train acc:0.6533333333333333, test acc:0.5522 ===\n",
      "train loss:1.0816537001424467\n",
      "train loss:1.1390307208946038\n",
      "train loss:1.1643488612255393\n",
      "=== epoch:273, train acc:0.65, test acc:0.5536 ===\n",
      "train loss:1.2777163037710346\n",
      "train loss:1.0675188956119637\n",
      "train loss:1.187700754644335\n",
      "=== epoch:274, train acc:0.6366666666666667, test acc:0.553 ===\n",
      "train loss:1.2431680544360812\n",
      "train loss:1.1307599880097379\n",
      "train loss:1.2715509361831985\n",
      "=== epoch:275, train acc:0.64, test acc:0.5542 ===\n",
      "train loss:1.0868500073375238\n",
      "train loss:1.0755900224953654\n",
      "train loss:1.0299717790962795\n",
      "=== epoch:276, train acc:0.63, test acc:0.5534 ===\n",
      "train loss:1.1177705478498936\n",
      "train loss:1.1848977294742717\n",
      "train loss:1.0911789783057029\n",
      "=== epoch:277, train acc:0.6433333333333333, test acc:0.5555 ===\n",
      "train loss:1.1825423374699011\n",
      "train loss:1.137278509406765\n",
      "train loss:1.0536637396890283\n",
      "=== epoch:278, train acc:0.64, test acc:0.5567 ===\n",
      "train loss:1.201143445840351\n",
      "train loss:1.1361198779745678\n",
      "train loss:1.16839479186149\n",
      "=== epoch:279, train acc:0.6433333333333333, test acc:0.5574 ===\n",
      "train loss:1.1678247436247269\n",
      "train loss:1.033028072236456\n",
      "train loss:1.0662880517298357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:280, train acc:0.64, test acc:0.5546 ===\n",
      "train loss:1.1569749942063634\n",
      "train loss:1.1508323245603111\n",
      "train loss:1.0233909382016895\n",
      "=== epoch:281, train acc:0.6433333333333333, test acc:0.5555 ===\n",
      "train loss:1.1083715845960027\n",
      "train loss:1.074965516937265\n",
      "train loss:1.1223920248892805\n",
      "=== epoch:282, train acc:0.65, test acc:0.5585 ===\n",
      "train loss:1.2210914178764178\n",
      "train loss:1.0600431211463919\n",
      "train loss:1.1292320072135016\n",
      "=== epoch:283, train acc:0.6533333333333333, test acc:0.5558 ===\n",
      "train loss:1.2135659156041918\n",
      "train loss:1.1926834094179888\n",
      "train loss:1.148163800784492\n",
      "=== epoch:284, train acc:0.6566666666666666, test acc:0.5553 ===\n",
      "train loss:1.1807771500059123\n",
      "train loss:1.0026984143315583\n",
      "train loss:1.1040987421809982\n",
      "=== epoch:285, train acc:0.6533333333333333, test acc:0.5558 ===\n",
      "train loss:1.0387004203835701\n",
      "train loss:1.098721680376772\n",
      "train loss:1.1377510889331646\n",
      "=== epoch:286, train acc:0.6566666666666666, test acc:0.5577 ===\n",
      "train loss:1.1552010271126654\n",
      "train loss:1.09159971795832\n",
      "train loss:1.0404176605924316\n",
      "=== epoch:287, train acc:0.6533333333333333, test acc:0.5602 ===\n",
      "train loss:1.127053150120271\n",
      "train loss:1.0663689425996528\n",
      "train loss:1.0338955994132748\n",
      "=== epoch:288, train acc:0.6666666666666666, test acc:0.5608 ===\n",
      "train loss:1.1235191994288634\n",
      "train loss:1.0425797198987303\n",
      "train loss:1.2775447495513632\n",
      "=== epoch:289, train acc:0.6566666666666666, test acc:0.5624 ===\n",
      "train loss:1.1152412322156888\n",
      "train loss:1.1850490657841215\n",
      "train loss:1.007646730158432\n",
      "=== epoch:290, train acc:0.6633333333333333, test acc:0.5619 ===\n",
      "train loss:1.112639624846378\n",
      "train loss:1.1185127983109646\n",
      "train loss:0.9708942985591722\n",
      "=== epoch:291, train acc:0.6666666666666666, test acc:0.5623 ===\n",
      "train loss:1.1062268103205624\n",
      "train loss:0.9291103730825796\n",
      "train loss:1.131947714334145\n",
      "=== epoch:292, train acc:0.66, test acc:0.5626 ===\n",
      "train loss:1.0484259022116194\n",
      "train loss:0.9285689586379737\n",
      "train loss:1.1563915110179075\n",
      "=== epoch:293, train acc:0.66, test acc:0.5616 ===\n",
      "train loss:0.9525696481234928\n",
      "train loss:1.109546687900272\n",
      "train loss:1.079499952068625\n",
      "=== epoch:294, train acc:0.66, test acc:0.5626 ===\n",
      "train loss:1.168095451027896\n",
      "train loss:1.1109129307554177\n",
      "train loss:1.1195958913671011\n",
      "=== epoch:295, train acc:0.6633333333333333, test acc:0.5645 ===\n",
      "train loss:1.0306245611496911\n",
      "train loss:0.9815427486602293\n",
      "train loss:1.1348964896399787\n",
      "=== epoch:296, train acc:0.6766666666666666, test acc:0.5666 ===\n",
      "train loss:1.030701281336364\n",
      "train loss:1.1408794711706534\n",
      "train loss:1.0455983146863692\n",
      "=== epoch:297, train acc:0.6633333333333333, test acc:0.5691 ===\n",
      "train loss:0.8678905148413572\n",
      "train loss:0.9585562211673984\n",
      "train loss:1.023663428041808\n",
      "=== epoch:298, train acc:0.6566666666666666, test acc:0.569 ===\n",
      "train loss:1.101887921196273\n",
      "train loss:1.0065052155940053\n",
      "train loss:0.9477584095143047\n",
      "=== epoch:299, train acc:0.6666666666666666, test acc:0.5686 ===\n",
      "train loss:1.0851356959733993\n",
      "train loss:0.9738885318200876\n",
      "train loss:1.0960514118946774\n",
      "=== epoch:300, train acc:0.67, test acc:0.5687 ===\n",
      "train loss:1.0595819745970938\n",
      "train loss:1.0185672764498142\n",
      "train loss:0.8553621268608012\n",
      "=== epoch:301, train acc:0.6733333333333333, test acc:0.5698 ===\n",
      "train loss:0.9141546137988095\n",
      "train loss:1.0054064589764828\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.5729\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "# 오버피팅을 재현하기 위해 학습 데이터 수를 줄임\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]\n",
    "\n",
    "# 드롭아웃 사용 유무와 비울 설정 ========================\n",
    "use_dropout = True  # 드롭아웃을 쓰지 않을 때는 False\n",
    "dropout_ratio = 0.2\n",
    "# ====================================================\n",
    "\n",
    "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
    "                              output_size=10, use_dropout=use_dropout, dropout_ration=dropout_ratio)\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=301, mini_batch_size=100,\n",
    "                  optimizer='sgd', optimizer_param={'lr': 0.01}, verbose=True)\n",
    "trainer.train()\n",
    "\n",
    "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
